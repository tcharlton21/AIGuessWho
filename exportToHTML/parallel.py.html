<html>
<head>
<title>parallel.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #cc7832;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
parallel.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Convenient parallelization of higher order functions. 
 
This module provides two helper functions, with appropriate fallbacks on 
Python 2 and on systems lacking support for synchronization mechanisms: 
 
- map_multiprocess 
- map_multithread 
 
These helpers work like Python 3's map, with two differences: 
 
- They don't guarantee the order of processing of 
  the elements of the iterable. 
- The underlying process/thread pools chop the iterable into 
  a number of chunks, so that for very long iterables using 
  a large value for chunksize can make the job complete much faster 
  than using the default value of 1. 
&quot;&quot;&quot;</span>

<span class="s1">__all__ = [</span><span class="s2">&quot;map_multiprocess&quot;</span><span class="s3">, </span><span class="s2">&quot;map_multithread&quot;</span><span class="s1">]</span>

<span class="s3">from </span><span class="s1">contextlib </span><span class="s3">import </span><span class="s1">contextmanager</span>
<span class="s3">from </span><span class="s1">multiprocessing </span><span class="s3">import </span><span class="s1">Pool </span><span class="s3">as </span><span class="s1">ProcessPool</span>
<span class="s3">from </span><span class="s1">multiprocessing </span><span class="s3">import </span><span class="s1">pool</span>
<span class="s3">from </span><span class="s1">multiprocessing.dummy </span><span class="s3">import </span><span class="s1">Pool </span><span class="s3">as </span><span class="s1">ThreadPool</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">Callable</span><span class="s3">, </span><span class="s1">Iterable</span><span class="s3">, </span><span class="s1">Iterator</span><span class="s3">, </span><span class="s1">TypeVar</span><span class="s3">, </span><span class="s1">Union</span>

<span class="s3">from </span><span class="s1">pip._vendor.requests.adapters </span><span class="s3">import </span><span class="s1">DEFAULT_POOLSIZE</span>

<span class="s1">Pool = Union[pool.Pool</span><span class="s3">, </span><span class="s1">pool.ThreadPool]</span>
<span class="s1">S = TypeVar(</span><span class="s2">&quot;S&quot;</span><span class="s1">)</span>
<span class="s1">T = TypeVar(</span><span class="s2">&quot;T&quot;</span><span class="s1">)</span>

<span class="s4"># On platforms without sem_open, multiprocessing[.dummy] Pool</span>
<span class="s4"># cannot be created.</span>
<span class="s3">try</span><span class="s1">:</span>
    <span class="s3">import </span><span class="s1">multiprocessing.synchronize  </span><span class="s4"># noqa</span>
<span class="s3">except </span><span class="s1">ImportError:</span>
    <span class="s1">LACK_SEM_OPEN = </span><span class="s3">True</span>
<span class="s3">else</span><span class="s1">:</span>
    <span class="s1">LACK_SEM_OPEN = </span><span class="s3">False</span>

<span class="s4"># Incredibly large timeout to work around bpo-8296 on Python 2.</span>
<span class="s1">TIMEOUT = </span><span class="s5">2000000</span>


<span class="s1">@contextmanager</span>
<span class="s3">def </span><span class="s1">closing(pool: Pool) -&gt; Iterator[Pool]:</span>
    <span class="s0">&quot;&quot;&quot;Return a context manager making sure the pool closes properly.&quot;&quot;&quot;</span>
    <span class="s3">try</span><span class="s1">:</span>
        <span class="s3">yield </span><span class="s1">pool</span>
    <span class="s3">finally</span><span class="s1">:</span>
        <span class="s4"># For Pool.imap*, close and join are needed</span>
        <span class="s4"># for the returned iterator to begin yielding.</span>
        <span class="s1">pool.close()</span>
        <span class="s1">pool.join()</span>
        <span class="s1">pool.terminate()</span>


<span class="s3">def </span><span class="s1">_map_fallback(</span>
    <span class="s1">func: Callable[[S]</span><span class="s3">, </span><span class="s1">T]</span><span class="s3">, </span><span class="s1">iterable: Iterable[S]</span><span class="s3">, </span><span class="s1">chunksize: int = </span><span class="s5">1</span>
<span class="s1">) -&gt; Iterator[T]:</span>
    <span class="s0">&quot;&quot;&quot;Make an iterator applying func to each element in iterable. 
 
    This function is the sequential fallback either on Python 2 
    where Pool.imap* doesn't react to KeyboardInterrupt 
    or when sem_open is unavailable. 
    &quot;&quot;&quot;</span>
    <span class="s3">return </span><span class="s1">map(func</span><span class="s3">, </span><span class="s1">iterable)</span>


<span class="s3">def </span><span class="s1">_map_multiprocess(</span>
    <span class="s1">func: Callable[[S]</span><span class="s3">, </span><span class="s1">T]</span><span class="s3">, </span><span class="s1">iterable: Iterable[S]</span><span class="s3">, </span><span class="s1">chunksize: int = </span><span class="s5">1</span>
<span class="s1">) -&gt; Iterator[T]:</span>
    <span class="s0">&quot;&quot;&quot;Chop iterable into chunks and submit them to a process pool. 
 
    For very long iterables using a large value for chunksize can make 
    the job complete much faster than using the default value of 1. 
 
    Return an unordered iterator of the results. 
    &quot;&quot;&quot;</span>
    <span class="s3">with </span><span class="s1">closing(ProcessPool()) </span><span class="s3">as </span><span class="s1">pool:</span>
        <span class="s3">return </span><span class="s1">pool.imap_unordered(func</span><span class="s3">, </span><span class="s1">iterable</span><span class="s3">, </span><span class="s1">chunksize)</span>


<span class="s3">def </span><span class="s1">_map_multithread(</span>
    <span class="s1">func: Callable[[S]</span><span class="s3">, </span><span class="s1">T]</span><span class="s3">, </span><span class="s1">iterable: Iterable[S]</span><span class="s3">, </span><span class="s1">chunksize: int = </span><span class="s5">1</span>
<span class="s1">) -&gt; Iterator[T]:</span>
    <span class="s0">&quot;&quot;&quot;Chop iterable into chunks and submit them to a thread pool. 
 
    For very long iterables using a large value for chunksize can make 
    the job complete much faster than using the default value of 1. 
 
    Return an unordered iterator of the results. 
    &quot;&quot;&quot;</span>
    <span class="s3">with </span><span class="s1">closing(ThreadPool(DEFAULT_POOLSIZE)) </span><span class="s3">as </span><span class="s1">pool:</span>
        <span class="s3">return </span><span class="s1">pool.imap_unordered(func</span><span class="s3">, </span><span class="s1">iterable</span><span class="s3">, </span><span class="s1">chunksize)</span>


<span class="s3">if </span><span class="s1">LACK_SEM_OPEN:</span>
    <span class="s1">map_multiprocess = map_multithread = _map_fallback</span>
<span class="s3">else</span><span class="s1">:</span>
    <span class="s1">map_multiprocess = _map_multiprocess</span>
    <span class="s1">map_multithread = _map_multithread</span>
</pre>
</body>
</html>